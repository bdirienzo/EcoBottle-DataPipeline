# üß© EcoBottle AR ‚Äì Data Warehouse & BI Dashboard

## üìä Descripci√≥n general
Este proyecto implementa un **mini‚Äìecosistema de datos comercial (online + offline)** para la empresa **EcoBottle AR**, con el objetivo de desarrollar un **pipeline ETL reproducible en Python** y un **dashboard anal√≠tico en Looker Studio** que permita monitorear ventas, usuarios activos, ticket promedio, NPS y desempe√±o por provincia y producto.

El flujo completo sigue buenas pr√°cticas de ingenier√≠a de datos y se basa en un **modelo estrella (Kimball)**.

---

## üß± Estructura del proyecto

```text
RAW (CSV, fuentes simuladas)
   ‚îî‚îÄ‚îÄ Extract  (etl/extract.py)
         ‚Üì
       Transform (etl/transform.py)
         ‚Üì
       Load      (etl/load.py)  ‚Üí  Data Warehouse (SQLite/PostgreSQL)
                                     ‚îî‚îÄ‚îÄ Modelo Estrella (DDL/star_schema.sql)
                                              ‚Üì
                                       Dashboard (Looker Studio)

```
---

Esa secci√≥n describe el flujo l√≥gico del proyecto desde la ingesta de archivos CSV hasta la visualizaci√≥n final en Looker Studio, manteniendo el formato limpio y consistente con el resto del README.

---

## üß© Esquema Estrella

### üß† Tabla de Hechos
| Campo | Descripci√≥n | Tipo |
|-------|--------------|------|
| sale_id | Identificador de la venta | INTEGER |
| date_id | FK a DimDate | INTEGER |
| customer_id | FK a DimCustomer | INTEGER |
| product_id | FK a DimProduct | INTEGER |
| store_id | FK a DimStore | INTEGER |
| channel_id | FK a DimChannel | INTEGER |
| amount | Monto total de la venta | FLOAT |
| quantity | Cantidad de √≠tems | INTEGER |

### üåê Tablas Dimensi√≥n
| Dimensi√≥n | Descripci√≥n |
|------------|--------------|
| **DimDate** | Fechas normalizadas (a√±o, mes, trimestre, d√≠a, etc.) |
| **DimCustomer** | Clientes con datos demogr√°ficos y de ubicaci√≥n |
| **DimProduct** | Productos con categor√≠a, precio y marca |
| **DimStore** | Tiendas f√≠sicas o sucursales |
| **DimProvince** | Provincias argentinas de operaci√≥n |
| **DimChannel** | Canal de venta (online/offline) |

---

## üßÆ KPIs Principales

| KPI | F√≥rmula / Fuente | Descripci√≥n |
|-----|------------------|--------------|
| **Ventas Totales** | SUM(amount) | Monto total vendido |
| **Usuarios Activos** | COUNT(DISTINCT customer_id) | Clientes con al menos una compra |
| **Ticket Promedio** | SUM(amount) / COUNT(DISTINCT sale_id) | Valor promedio por transacci√≥n |
| **NPS (Net Promoter Score)** | %Promotores - %Detractores | Nivel de satisfacci√≥n y lealtad del cliente |
| **Ventas por Provincia** | SUM(amount) GROUP BY province | Distribuci√≥n geogr√°fica |
| **Ranking de Productos** | SUM(amount) GROUP BY product | Identificaci√≥n de productos top |

---

## ‚öôÔ∏è Pipeline ETL

### 1Ô∏è‚É£ Extract
Lectura de archivos `.csv` desde la carpeta `RAW`:
```bash
python -m etl.extract
```

### 2Ô∏è‚É£ Transform
Limpieza, estandarizaci√≥n de campos y creaci√≥n de nuevas m√©tricas derivadas.  
Incluye:
- Conversi√≥n de tipos y manejo de valores nulos  
- Integraci√≥n de tablas (joins entre productos, tiendas y canales)  
- C√°lculo de m√©tricas base: monto, cantidad y fecha de venta  
- Normalizaci√≥n de provincias y canales
```bash
python -m etl.transform 
```

### 3Ô∏è‚É£ Load
Carga de los datos transformados en el modelo estrella definido en SQL.
Se utiliza una base local (por defecto SQLite), aunque el dise√±o es compatible con PostgreSQL.
```bash
python -m etl.load
```

### ‚ñ∂Ô∏è Ejecuci√≥n completa del pipeline
Ejecuta los tres pasos anteriores en secuencia, registrando logs del proceso:
```bash
python -m etl.run_pipeline
```
---
Los logs de ejecuci√≥n se almacenan en /logs/pipeline.log e incluyen el conteo de filas procesadas por tabla.